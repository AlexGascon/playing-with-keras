{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation with (larger) LSTM Recurrent Neural Networks\n",
    "\n",
    "By Alex Gasc√≥n Bononad - alexgascon.93@gmail.com\n",
    "\n",
    "## 0. Introduction\n",
    "\n",
    "### 0.1. Introduction to the Notebook\n",
    "In this notebook we're going to end what we started in the first one of this repository (#1 Text generation with (larger) LSTM Recurrent Neural Networks): we''ll follow the following tutorial: http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/ [1] to create a LSTM RNN capable of generating text. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Description of the problem\n",
    "\n",
    "In the previous part we were able to achieve this, but the obtained NN was too small and the generated text wasn't understandable enough. That's why now we're going to take what we learned and tested and expand it in order to get a better functional example. \n",
    "\n",
    "Besides, in this case, we're going to change the book we'll use to train our network: instead of Alice in Wonderland, the book to use will be \"El ingenioso hidalgo don Quijote de la Mancha\", one of the most famous books of Spanish literature. We have also obtained it from [Project Gutenberg](http://www.gutenberg.org/cache/epub/2000/pg2000.txt), but you can find the version without headers and footers in the same folder of this no"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
