{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving text generation with (larger) LSTM RNN\n",
    "\n",
    "By Alex Gasc√≥n Bononad - alexgascon.93@gmail.com\n",
    "\n",
    "## 0. Introduction\n",
    "\n",
    "### 0.1. Introduction to the Notebook\n",
    "The main objective of this notebook is to improve the work we ended with on the notebook #2 of this repository, in order to make more accurate predicitons\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Description\n",
    "If you remember properly, in the last notebook we ended up having a trained model that was able to generate text by predicting the next character of a 100 character string. And, although the text was almost perfect grammatically, it wasn't it so much syntactically or semantically, as the model repeated the same string over and over again.\n",
    "\n",
    "Now, what we're going to do is to try different approaches and see the effects they have on the model, in order to improve those problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing improvements\n",
    "\n",
    "### 2.1. Randomizing our prediction\n",
    "The first approach we're going to try is to randomize our character prediction. However, with an important detail: the random distribution we'll use will be given by the output of our RNN.\n",
    "\n",
    "Our RNN outputs an array of floating point numbers compressed between 0 and 1, each one representing the probability of the character in that position of being the most suitable option for the prediction. However, currently we search for the most suitable one and select it as our result. What we're going to try now, instead, is to randomize our prediction while taking into account this probabilities. \n",
    "\n",
    "We'll achieve this by using the output array of our RNN as the [Density Probability Function](https://es.wikipedia.org/wiki/Funci%C3%B3n_de_densidad_de_probabilidad) [1] for our randomized prediction. As this array contains the probability of each character, the sum of all its elements will always be 1 (because the probability of our prediction being a character, no matter which one, is 1). Let's see it with an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
